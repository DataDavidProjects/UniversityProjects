{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "503877cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from os.path import isfile, join\n",
    "import string\n",
    "import time\n",
    "import re\n",
    "from string import punctuation\n",
    "import sys\n",
    "\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords \n",
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.preprocessing import LabelEncoder , StandardScaler , MaxAbsScaler \n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.base import TransformerMixin\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import *\n",
    "from sklearn.feature_extraction.text import CountVectorizer ,TfidfVectorizer\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.layers import Dense, Input, Dropout\n",
    "from keras import Sequential\n",
    "from keras import metrics\n",
    "\n",
    "\n",
    "def timing(f):\n",
    "    def wrap(*args, **kwargs):\n",
    "        time1 = time.time()\n",
    "        ret = f(*args, **kwargs)\n",
    "        time2 = time.time()\n",
    "        print('{:s} function took {:.3f} ms'.format(f.__name__, (time2-time1)*1000.0))\n",
    "\n",
    "        return ret\n",
    "    return wrap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "479392da",
   "metadata": {},
   "source": [
    "# Data Acquisition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d45a988d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "computer      2936\n",
       "science       1779\n",
       "politics      1575\n",
       "sport         1197\n",
       "automobile    1192\n",
       "religion       976\n",
       "medicine       594\n",
       "sales          585\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#______________________________________________________ DATA INGESTION___________________________________________________________________\n",
    "dataset = fetch_20newsgroups(subset='train', remove=('headers', 'footers', 'quotes'), shuffle=True, random_state=42)\n",
    "df = pd.DataFrame()\n",
    "df['text'] = dataset.data\n",
    "df['source'] = dataset.target\n",
    "label=[]\n",
    "for i in df['source']:\n",
    "    label.append(dataset.target_names[i])\n",
    "df['label']=label\n",
    "df.drop(['source'],axis=1,inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "#++++++++++++++++++++++++++++++++++++++++Macro Categories++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
    "key_categories = ['politics','sport','religion','computer','sales','automobile','science','medicine']\n",
    "cat_dict = {\n",
    "**dict.fromkeys(['talk.politics.misc','talk.politics.guns','talk.politics.mideast'],'politics'),\n",
    "**dict.fromkeys( ['rec.sport.hockey','rec.sport.baseball'],'sport'),\n",
    "**dict.fromkeys( ['soc.religion.christian','talk.religion.misc'],'religion'),\n",
    "**dict.fromkeys(['comp.windows.x','comp.sys.ibm.pc.hardware','comp.os.ms-windows.misc','comp.graphics','comp.sys.mac.hardware'],'computer'),\n",
    "**dict.fromkeys( ['misc.forsale'],'sales'),\n",
    "**dict.fromkeys( ['rec.autos','rec.motorcycles'],'automobile'),\n",
    "**dict.fromkeys( ['sci.crypt','sci.electronics','sci.space'],'science'),\n",
    "**dict.fromkeys( ['sci.med'],'medicine') \n",
    "}\n",
    "df['label']=df['label'].map(cat_dict)\n",
    "#++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
    "\n",
    "label_encoder = LabelEncoder()  \n",
    "# Encode labels in column \n",
    "df['target']= label_encoder.fit_transform(df['label'])\n",
    "\n",
    "df = df.sample(frac = 1)\n",
    "# dependent and independent variable\n",
    "X = df['text']\n",
    "y = df['target']\n",
    "\n",
    "df['label'].value_counts()\n",
    "#_____________________________________________________________________________________________________________________________________________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8b150d20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "computer      2936\n",
       "science       1779\n",
       "politics      1575\n",
       "sport         1197\n",
       "automobile    1192\n",
       "religion       976\n",
       "medicine       594\n",
       "sales          585\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2579e25",
   "metadata": {},
   "source": [
    "### Downsampling Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e8698060",
   "metadata": {},
   "outputs": [],
   "source": [
    "def downsample(df):\n",
    "    minority_frequency  = df['label'].value_counts()[-1]\n",
    "    minority_label = df['label'].value_counts().index[-1]\n",
    "    \n",
    "    df_balanced = df.loc[df['label'] == minority_label , : ].sample(minority_frequency).copy()\n",
    "    df_balanced = df_balanced.reset_index(drop = True)\n",
    "    \n",
    "    label_list = df['label'].value_counts().index.tolist()\n",
    "    #Sample and concat\n",
    "    for label in label_list:\n",
    "        if label != minority_label:\n",
    "            sample_df = df.loc[df['label'] == label , : ].sample(minority_frequency).copy()\n",
    "            df_balanced = pd.concat([ df_balanced , sample_df],axis = 0 , ignore_index=True) \n",
    "    # Shuffle data\n",
    "    df_balanced = df_balanced.sample(frac = 1).reset_index(drop = True)\n",
    "    \n",
    "    return df_balanced\n",
    "\n",
    "df_balanced = downsample(df)\n",
    "# dependent and independent variable\n",
    "X = df_balanced['text']\n",
    "y = df_balanced['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9fe7f41e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>7</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>2</th>\n",
       "      <th>6</th>\n",
       "      <th>0</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>target</th>\n",
       "      <td>585</td>\n",
       "      <td>585</td>\n",
       "      <td>585</td>\n",
       "      <td>585</td>\n",
       "      <td>585</td>\n",
       "      <td>585</td>\n",
       "      <td>585</td>\n",
       "      <td>585</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          1    7    4    5    2    6    0    3\n",
       "target  585  585  585  585  585  585  585  585"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Proportions of labels\n",
    "pd.DataFrame(y.value_counts()).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f693f161",
   "metadata": {},
   "outputs": [],
   "source": [
    "# doc  = nlp('I  @  1223 am happy for your new promotion')\n",
    "# tokens_list  = [ token for token in doc if not token.is_punct and not token.is_space and token.is_alpha]\n",
    "# filter_token_sw = [token.lemma_ for token in tokens_list if token.lower_ not in stopwords.words('english')]\n",
    "# filter_token_sw"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1a07a4d",
   "metadata": {},
   "source": [
    "# Preprocessing Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9e866558",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Need OPT\n",
    "def spacy_preprocessing(text_format):\n",
    "        \n",
    "    def combine_text(list_of_text):\n",
    "            combined_text = ' '.join(list_of_text)\n",
    "            return combined_text\n",
    "        \n",
    "    doc  = nlp(text_format)\n",
    "    tokens_list  = [ token for token in doc if not token.is_punct and not token.is_space and token.is_alpha]\n",
    "    filter_token_sw = [token.lemma_ for token in tokens_list if token.lower_ not in stopwords.words('english')]\n",
    "   \n",
    "    return combine_text(filter_token_sw)\n",
    "    \n",
    "vec_prop = np.vectorize(spacy_preprocessing)\n",
    "pipe_spacy_preprocessing = FunctionTransformer(vec_prop)\n",
    "\n",
    "\n",
    "\n",
    "class DenseTransformer(TransformerMixin):\n",
    "\n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None, **fit_params):\n",
    "        return X.todense()\n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "prep_pipeline = Pipeline([\n",
    "                    ('text_preprocessing', pipe_spacy_preprocessing )\n",
    "                    ])\n",
    "\n",
    "# DEFINE LABELS IN OHE FORMAT\n",
    "yc = tf.keras.utils.to_categorical(y,num_classes = 20,dtype=int )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7f0cbe43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4680,)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ee7e699",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "878c833a",
   "metadata": {},
   "source": [
    "# Model Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c15e9479",
   "metadata": {},
   "source": [
    "### Hyperparameters fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "22164919",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF IDF DIMENSION will affect the model \n",
    "matrix_features  = 2500\n",
    "\n",
    "n_classes =y.nunique()\n",
    "def create_model(optimizer=\"adam\",\n",
    "                 dense_layer_sizes = False,\n",
    "                 dropout=0.1, init='uniform',\n",
    "                 features=matrix_features,neurons=20,\n",
    "                 n_classes = n_classes ):\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Dense(neurons, activation='relu', input_shape=(features,),kernel_initializer=init)) #\n",
    "    model.add(Dropout(dropout), )    \n",
    "\n",
    "    #for layer_size in dense_layer_sizes:\n",
    "    #   model.add(Dense(layer_size, activation='relu'))\n",
    "    #   model.add(Dropout(dropout), )    \n",
    "    \n",
    "    model.add(Dense(n_classes, activation='softmax'))\n",
    "    model.compile(loss='sparse_categorical_crossentropy',\n",
    "                  optimizer=optimizer,\n",
    "                  metrics=['sparse_categorical_accuracy'])\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#dense_layer_sizes = [[] , []]\n",
    "#param_grid = dict(neurons=neurons, epochs = epochs, batch_size =batch_size)\n",
    "\n",
    "param_grid = {\n",
    "    'tfidf__ngram_range': [(1,1), (1,2)],\n",
    "    'kc__epochs': [20,30,50],\n",
    "    'kc__neurons': [10, 20, 30, 100],\n",
    "    'kc__batch_size':[16, 32,50],\n",
    "    'kc__dropout': [ 0.3, 0.1, 0]\n",
    "}\n",
    "\n",
    "\n",
    "#StratifiedKFold(n_splits=2, shuffle=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b751e628",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\david\\AppData\\Local\\Temp/ipykernel_31904/1029838963.py:5: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead.\n",
      "  ('kc' ,KerasClassifier(build_fn=create_model, verbose = 0))\n"
     ]
    }
   ],
   "source": [
    "model_pipeline = Pipeline([\n",
    "                    ('tfidf', TfidfVectorizer(use_idf = True,max_features=2500)),\n",
    "                    ('sparse_to_dense',DenseTransformer()),\n",
    "                    ('scaler', MaxAbsScaler()),\n",
    "                    ('kc' ,KerasClassifier(build_fn=create_model, verbose = 0))\n",
    "])\n",
    "\n",
    "folds = 3\n",
    "skf = StratifiedKFold(n_splits=folds, shuffle = True, random_state = 1001)\n",
    "grid = GridSearchCV(estimator=model_pipeline,\n",
    "                    verbose=1,\n",
    "                    cv=skf.split(X,y),\n",
    "                    param_grid=param_grid,\n",
    "                    scoring='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8c2c725d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-96ec21cc-172c-4dd5-a75e-a37ccac3776b {color: black;background-color: white;}#sk-96ec21cc-172c-4dd5-a75e-a37ccac3776b pre{padding: 0;}#sk-96ec21cc-172c-4dd5-a75e-a37ccac3776b div.sk-toggleable {background-color: white;}#sk-96ec21cc-172c-4dd5-a75e-a37ccac3776b label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-96ec21cc-172c-4dd5-a75e-a37ccac3776b div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-96ec21cc-172c-4dd5-a75e-a37ccac3776b div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-96ec21cc-172c-4dd5-a75e-a37ccac3776b input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-96ec21cc-172c-4dd5-a75e-a37ccac3776b div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-96ec21cc-172c-4dd5-a75e-a37ccac3776b div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-96ec21cc-172c-4dd5-a75e-a37ccac3776b input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-96ec21cc-172c-4dd5-a75e-a37ccac3776b div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-96ec21cc-172c-4dd5-a75e-a37ccac3776b div.sk-estimator:hover {background-color: #d4ebff;}#sk-96ec21cc-172c-4dd5-a75e-a37ccac3776b div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-96ec21cc-172c-4dd5-a75e-a37ccac3776b div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-96ec21cc-172c-4dd5-a75e-a37ccac3776b div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 2em;bottom: 0;left: 50%;}#sk-96ec21cc-172c-4dd5-a75e-a37ccac3776b div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;}#sk-96ec21cc-172c-4dd5-a75e-a37ccac3776b div.sk-item {z-index: 1;}#sk-96ec21cc-172c-4dd5-a75e-a37ccac3776b div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;}#sk-96ec21cc-172c-4dd5-a75e-a37ccac3776b div.sk-parallel::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 2em;bottom: 0;left: 50%;}#sk-96ec21cc-172c-4dd5-a75e-a37ccac3776b div.sk-parallel-item {display: flex;flex-direction: column;position: relative;background-color: white;}#sk-96ec21cc-172c-4dd5-a75e-a37ccac3776b div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-96ec21cc-172c-4dd5-a75e-a37ccac3776b div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-96ec21cc-172c-4dd5-a75e-a37ccac3776b div.sk-parallel-item:only-child::after {width: 0;}#sk-96ec21cc-172c-4dd5-a75e-a37ccac3776b div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;position: relative;}#sk-96ec21cc-172c-4dd5-a75e-a37ccac3776b div.sk-label label {font-family: monospace;font-weight: bold;background-color: white;display: inline-block;line-height: 1.2em;}#sk-96ec21cc-172c-4dd5-a75e-a37ccac3776b div.sk-label-container {position: relative;z-index: 2;text-align: center;}#sk-96ec21cc-172c-4dd5-a75e-a37ccac3776b div.sk-container {display: inline-block;position: relative;}</style><div id=\"sk-96ec21cc-172c-4dd5-a75e-a37ccac3776b\" class\"sk-top-container\"><div class=\"sk-container\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"1afcb451-d9fe-46af-a067-0f3a1b1664b8\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"1afcb451-d9fe-46af-a067-0f3a1b1664b8\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=<generator object _BaseKFold.split at 0x0000018B79DE3510>,\n",
       "             estimator=Pipeline(steps=[('tfidf',\n",
       "                                        TfidfVectorizer(max_features=2500)),\n",
       "                                       ('sparse_to_dense',\n",
       "                                        <__main__.DenseTransformer object at 0x0000018B79DE57C0>),\n",
       "                                       ('scaler', MaxAbsScaler()),\n",
       "                                       ('kc',\n",
       "                                        <keras.wrappers.scikit_learn.KerasClassifier object at 0x0000018B79DE5A30>)]),\n",
       "             param_grid={'kc__batch_size': [16, 32, 50],\n",
       "                         'kc__dropout': [0.3, 0.1, 0],\n",
       "                         'kc__epochs': [20, 30, 50],\n",
       "                         'kc__neurons': [10, 20, 30, 100],\n",
       "                         'tfidf__ngram_range': [(1, 1), (1, 2)]},\n",
       "             scoring='accuracy', verbose=1)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"22ab6054-23a6-498a-bf70-bdf215d54694\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"22ab6054-23a6-498a-bf70-bdf215d54694\">TfidfVectorizer</label><div class=\"sk-toggleable__content\"><pre>TfidfVectorizer(max_features=2500)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"24eb918a-2a99-4da3-8300-9809db083b72\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"24eb918a-2a99-4da3-8300-9809db083b72\">DenseTransformer</label><div class=\"sk-toggleable__content\"><pre><__main__.DenseTransformer object at 0x0000018B79DE57C0></pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"9c2fa118-2bc7-476c-b8ef-ce365e53ee13\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"9c2fa118-2bc7-476c-b8ef-ce365e53ee13\">MaxAbsScaler</label><div class=\"sk-toggleable__content\"><pre>MaxAbsScaler()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"458313c5-c074-422f-a722-d24ff92e1087\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"458313c5-c074-422f-a722-d24ff92e1087\">KerasClassifier</label><div class=\"sk-toggleable__content\"><pre><keras.wrappers.scikit_learn.KerasClassifier object at 0x0000018B79DE5A30></pre></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=<generator object _BaseKFold.split at 0x0000018B79DE3510>,\n",
       "             estimator=Pipeline(steps=[('tfidf',\n",
       "                                        TfidfVectorizer(max_features=2500)),\n",
       "                                       ('sparse_to_dense',\n",
       "                                        <__main__.DenseTransformer object at 0x0000018B79DE57C0>),\n",
       "                                       ('scaler', MaxAbsScaler()),\n",
       "                                       ('kc',\n",
       "                                        <keras.wrappers.scikit_learn.KerasClassifier object at 0x0000018B79DE5A30>)]),\n",
       "             param_grid={'kc__batch_size': [16, 32, 50],\n",
       "                         'kc__dropout': [0.3, 0.1, 0],\n",
       "                         'kc__epochs': [20, 30, 50],\n",
       "                         'kc__neurons': [10, 20, 30, 100],\n",
       "                         'tfidf__ngram_range': [(1, 1), (1, 2)]},\n",
       "             scoring='accuracy', verbose=1)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import set_config\n",
    "set_config(display='diagram')\n",
    "\n",
    "grid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec153575",
   "metadata": {},
   "source": [
    "#### Grid Search "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dd3a1d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# limit = 100\n",
    "# X_p = prep_pipeline.fit_transform(X[:limit]).toarray()\n",
    "# X_p.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "429ccbc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.utils.multiclass import type_of_target\n",
    "# type_of_target(y) , type_of_target(yc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f82b19e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_t = prep_pipeline.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95dcbd45",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "t0 = time.time()\n",
    "grid_fitted = grid.fit(X_t,y) # Pipe line fitted with preprocessed clean text spacy\n",
    "results  =  pd.DataFrame(grid_fitted.cv_results_).sort_values('rank_test_score')\n",
    "\n",
    "t1 = time.time()\n",
    "delta = t1-t0\n",
    "print(f'Tuning Time s: {round(delta,3)}')\n",
    "results.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51ee307d",
   "metadata": {},
   "source": [
    "## Fit the Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26d29688",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST SAMPLE\n",
    "# limit = 1000\n",
    "\n",
    "# model = create_model(neurons=20)\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd28c83d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#+++++++++++++++++++++++ BEST PIPE PARAMS ++++++++++++++++++++++++++++++++\n",
    "opt_pipeline  = grid_fitted.best_estimator_\n",
    "\n",
    "t0 = time.time()\n",
    "fitted_pipe = opt_pipeline.fit(X,y)\n",
    "time.time() - t0 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac5fbfd7",
   "metadata": {},
   "source": [
    "# Testing Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcfa9371",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = fetch_20newsgroups(subset='test', remove=('headers', 'footers', 'quotes'), shuffle=True, random_state=42)\n",
    "df = pd.DataFrame()\n",
    "df['text'] = dataset.data\n",
    "df['source'] = dataset.target\n",
    "label=[]\n",
    "for i in df['source']:\n",
    "    label.append(dataset.target_names[i])\n",
    "df['label']=label\n",
    "df.drop(['source'],axis=1,inplace=True)\n",
    "\n",
    "#++++++++++++++++++++++++++++++++++++++++Macro Categories++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
    "key_categories = ['politics','sport','religion','computer','sales','automobile','science','medicine']\n",
    "cat_dict = {\n",
    "**dict.fromkeys(['talk.politics.misc','talk.politics.guns','talk.politics.mideast'],'politics'),\n",
    "**dict.fromkeys( ['rec.sport.hockey','rec.sport.baseball'],'sport'),\n",
    "**dict.fromkeys( ['soc.religion.christian','talk.religion.misc'],'religion'),\n",
    "**dict.fromkeys(['comp.windows.x','comp.sys.ibm.pc.hardware','comp.os.ms-windows.misc','comp.graphics','comp.sys.mac.hardware'],'computer'),\n",
    "**dict.fromkeys( ['misc.forsale'],'sales'),\n",
    "**dict.fromkeys( ['rec.autos','rec.motorcycles'],'automobile'),\n",
    "**dict.fromkeys( ['sci.crypt','sci.electronics','sci.space'],'science'),\n",
    "**dict.fromkeys( ['sci.med'],'medicine') \n",
    "}\n",
    "df['label']=df['label'].map(cat_dict)\n",
    "#++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
    "\n",
    "\n",
    "label_encoder = LabelEncoder()  \n",
    "# Encode labels in column 'species'.\n",
    "df['target']= label_encoder.fit_transform(df['label'])\n",
    "\n",
    "\n",
    "#++++++++++++++++++++++++ PICK RANDOM 30 % OF TEST++++++++++++++++++++++++++\n",
    "df = df.sample(frac = 1) \n",
    "# dependent and independent variable\n",
    "X_test = df['text']\n",
    "y_test = df['target']\n",
    "#_____________________________________________________________________________________________________________________________________________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7d6ca9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "124b275c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred  = opt_pipeline.predict(X_test)\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcc19334",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4ca4df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_proba_pred = pd.DataFrame(fitted_pipe.predict_proba(X_test))\n",
    "dist_proba_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb14ca7c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
