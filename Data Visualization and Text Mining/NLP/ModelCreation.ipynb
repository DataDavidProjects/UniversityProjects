{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d30fa0bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from os.path import isfile, join\n",
    "import string\n",
    "import time\n",
    "import re\n",
    "from string import punctuation\n",
    "import sys\n",
    "\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords \n",
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.preprocessing import LabelEncoder , StandardScaler , MaxAbsScaler \n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.base import TransformerMixin\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import *\n",
    "from sklearn.feature_extraction.text import CountVectorizer ,TfidfVectorizer\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.layers import Dense, Input, Dropout\n",
    "from keras import Sequential\n",
    "from keras import metrics\n",
    "\n",
    "\n",
    "def timing(f):\n",
    "    def wrap(*args, **kwargs):\n",
    "        time1 = time.time()\n",
    "        ret = f(*args, **kwargs)\n",
    "        time2 = time.time()\n",
    "        print('{:s} function took {:.3f} ms'.format(f.__name__, (time2-time1)*1000.0))\n",
    "\n",
    "        return ret\n",
    "    return wrap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e400003b",
   "metadata": {},
   "source": [
    "# Data Acquisition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1fafe439",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "computer      2936\n",
       "science       1779\n",
       "politics      1575\n",
       "sport         1197\n",
       "automobile    1192\n",
       "religion       976\n",
       "medicine       594\n",
       "sales          585\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#______________________________________________________ DATA INGESTION___________________________________________________________________\n",
    "dataset = fetch_20newsgroups(subset='train', remove=('headers', 'footers', 'quotes'), shuffle=True, random_state=42)\n",
    "df = pd.DataFrame()\n",
    "df['text'] = dataset.data\n",
    "df['source'] = dataset.target\n",
    "label=[]\n",
    "for i in df['source']:\n",
    "    label.append(dataset.target_names[i])\n",
    "df['label']=label\n",
    "df.drop(['source'],axis=1,inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "#++++++++++++++++++++++++++++++++++++++++Macro Categories++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
    "key_categories = ['politics','sport','religion','computer','sales','automobile','science','medicine']\n",
    "cat_dict = {\n",
    "**dict.fromkeys(['talk.politics.misc','talk.politics.guns','talk.politics.mideast'],'politics'),\n",
    "**dict.fromkeys( ['rec.sport.hockey','rec.sport.baseball'],'sport'),\n",
    "**dict.fromkeys( ['soc.religion.christian','talk.religion.misc'],'religion'),\n",
    "**dict.fromkeys(['comp.windows.x','comp.sys.ibm.pc.hardware','comp.os.ms-windows.misc','comp.graphics','comp.sys.mac.hardware'],'computer'),\n",
    "**dict.fromkeys( ['misc.forsale'],'sales'),\n",
    "**dict.fromkeys( ['rec.autos','rec.motorcycles'],'automobile'),\n",
    "**dict.fromkeys( ['sci.crypt','sci.electronics','sci.space'],'science'),\n",
    "**dict.fromkeys( ['sci.med'],'medicine') \n",
    "}\n",
    "df['label']=df['label'].map(cat_dict)\n",
    "#++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
    "\n",
    "label_encoder = LabelEncoder()  \n",
    "# Encode labels in column \n",
    "df['target']= label_encoder.fit_transform(df['label'])\n",
    "\n",
    "df = df.sample(frac = 1)\n",
    "# dependent and independent variable\n",
    "X = df['text']\n",
    "y = df['target']\n",
    "\n",
    "df['label'].value_counts()\n",
    "#_____________________________________________________________________________________________________________________________________________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "68b210ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>6</th>\n",
       "      <th>3</th>\n",
       "      <th>7</th>\n",
       "      <th>0</th>\n",
       "      <th>4</th>\n",
       "      <th>2</th>\n",
       "      <th>5</th>\n",
       "      <th>8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>target</th>\n",
       "      <td>2936</td>\n",
       "      <td>1779</td>\n",
       "      <td>1575</td>\n",
       "      <td>1197</td>\n",
       "      <td>1192</td>\n",
       "      <td>976</td>\n",
       "      <td>594</td>\n",
       "      <td>585</td>\n",
       "      <td>480</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           1     6     3     7     0    4    2    5    8\n",
       "target  2936  1779  1575  1197  1192  976  594  585  480"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Proportions of labels\n",
    "pd.DataFrame(y.value_counts()).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "96f8bc9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1065</th>\n",
       "      <td>Could someone please help me find a program ...</td>\n",
       "      <td>comp.graphics</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10347</th>\n",
       "      <td>\\n\\n\\nBobby, there's a question here that I ju...</td>\n",
       "      <td>alt.atheism</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6257</th>\n",
       "      <td></td>\n",
       "      <td>alt.atheism</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9325</th>\n",
       "      <td>The Orders for the Turkish Extermination of th...</td>\n",
       "      <td>talk.politics.mideast</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9823</th>\n",
       "      <td>\\nIt depends on the bike. Once you've found a ...</td>\n",
       "      <td>rec.motorcycles</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  \\\n",
       "1065     Could someone please help me find a program ...   \n",
       "10347  \\n\\n\\nBobby, there's a question here that I ju...   \n",
       "6257                                                       \n",
       "9325   The Orders for the Turkish Extermination of th...   \n",
       "9823   \\nIt depends on the bike. Once you've found a ...   \n",
       "\n",
       "                       label  target  \n",
       "1065           comp.graphics       1  \n",
       "10347            alt.atheism       0  \n",
       "6257             alt.atheism       0  \n",
       "9325   talk.politics.mideast      17  \n",
       "9823         rec.motorcycles       8  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1849613",
   "metadata": {},
   "source": [
    "# Preprocessing Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "458033d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Need OPT\n",
    "def spacy_preprocessing(text_format):\n",
    "        \n",
    "    def combine_text(list_of_text):\n",
    "            combined_text = ' '.join(list_of_text)\n",
    "            return combined_text\n",
    "        \n",
    "    doc  = nlp(text_format)\n",
    "    tokens_list  = [ token.lemma_ for token in doc if not token.is_punct and not token.is_space and token.is_alpha]\n",
    "    filter_token_sw = [token.lower() for token in tokens_list if token.lower() not in stopwords.words('english')]\n",
    "   \n",
    "    return combine_text(filter_token_sw)\n",
    "    \n",
    "vec_prop = np.vectorize(spacy_preprocessing)\n",
    "pipe_spacy_preprocessing = FunctionTransformer(vec_prop)\n",
    "\n",
    "\n",
    "\n",
    "class DenseTransformer(TransformerMixin):\n",
    "\n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None, **fit_params):\n",
    "        return X.todense()\n",
    "    \n",
    "\n",
    "    \n",
    "# TF IDF DIMENSION will affect the model \n",
    "matrix_features  = 2500\n",
    "prep_pipeline = Pipeline([\n",
    "                    ('text_preprocessing', pipe_spacy_preprocessing ),\n",
    "                    ('tfidf', TfidfVectorizer(use_idf = True, max_features=matrix_features)),\n",
    "                    ('sparse_to_dense',DenseTransformer()),\n",
    "                    ('scaler', MaxAbsScaler())\n",
    "                    \n",
    "                    ])\n",
    "\n",
    "# DEFINE LABELS IN OHE FORMAT\n",
    "yc = tf.keras.utils.to_categorical(y,num_classes = 20,dtype=int )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6582fa3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11314,)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "004333ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_t = prep_pipeline.fit_transform(X).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e39cf4bb",
   "metadata": {},
   "source": [
    "# Model Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08debe1c",
   "metadata": {},
   "source": [
    "### Hyperparameters fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99ce67ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import set_config\n",
    "set_config(display='diagram')\n",
    "\n",
    "prep_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54ac8905",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes = len(set(label))\n",
    "\n",
    "\n",
    "def create_model(optimizer=\"adam\",\n",
    "                 dense_layer_sizes = False,\n",
    "                 dropout=0.1, init='uniform',\n",
    "                 features=matrix_features,neurons=20,\n",
    "                 n_classes = n_classes ):\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Dense(neurons, activation='relu', input_shape=(features,), kernel_initializer=init,)) \n",
    "    \n",
    "    #for layer_size in dense_layer_sizes:\n",
    "    #   model.add(Dense(layer_size, activation='relu'))\n",
    "    #   model.add(Dropout(dropout), )    \n",
    "    model.add(Dense(n_classes, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer=optimizer,\n",
    "                  metrics=[tf.keras.metrics.AUC()])\n",
    "    return model\n",
    "\n",
    "kears_estimator = KerasClassifier(build_fn=create_model,\n",
    "                                  verbose=1,\n",
    "                                  batch_size=2**5,\n",
    "                                  epochs = 15)\n",
    "\n",
    "neurons=[10,50,100,300,500,1000]\n",
    "epochs = [5,10,30,50]\n",
    "batch_size = [2,4,10,20,50,100]\n",
    "\n",
    "#dense_layer_sizes = [[] , []]\n",
    "\n",
    "param_grid = dict(neurons=neurons, epochs = epochs, batch_size =batch_size)\n",
    "StratifiedKFold(n_splits=2, shuffle=True)\n",
    "grid = GridSearchCV(estimator=kears_estimator,\n",
    "                    verbose=1,\n",
    "                    cv=5,\n",
    "                    param_grid=param_grid,scoring='roc_auc')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddc18594",
   "metadata": {},
   "source": [
    "#### Grid Search Issue multilabel multiclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb8d3f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# limit = 100\n",
    "# X_p = prep_pipeline.fit_transform(X[:limit]).toarray()\n",
    "# X_p.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0f09bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.utils.multiclass import type_of_target\n",
    "# type_of_target(y) , type_of_target(yc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "599b92cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid_results = grid.fit(X_p,yc)\n",
    "# results  =  pd.DataFrame(grid_results.cv_results_).sort_values('rank_test_score')\n",
    "# results.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93288085",
   "metadata": {},
   "source": [
    "## Fit the Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "228176b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST SAMPLE\n",
    "limit = 1000\n",
    "yp =  tf.keras.utils.to_categorical(y[:limit],dtype=int )\n",
    "X_p = prep_pipeline.fit_transform(X[:limit])\n",
    "model = create_model(neurons=20).fit(X_p,yp,epochs  = 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b57bfe04",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_pipeline = Pipeline([\n",
    "                    ('text_preprocessing', pipe_spacy_preprocessing ),\n",
    "                    ('tfidf', TfidfVectorizer(use_idf = True, max_features=2500)),\n",
    "                    ('sparse_to_dense',DenseTransformer()),\n",
    "                    ('scaler', MaxAbsScaler()),\n",
    "                    ('clf' ,kears_estimator )\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0a7a6a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ceb0498",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "t0 = time.time()\n",
    "fitted_pipe = model_pipeline.fit(X,yc)\n",
    "time.time() - t0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81ca3600",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c7868232",
   "metadata": {},
   "source": [
    "# Testing Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beddce03",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = fetch_20newsgroups(subset='test', remove=('headers', 'footers', 'quotes'), shuffle=True, random_state=42)\n",
    "df = pd.DataFrame()\n",
    "df['text'] = dataset.data\n",
    "df['source'] = dataset.target\n",
    "label=[]\n",
    "for i in df['source']:\n",
    "    label.append(dataset.target_names[i])\n",
    "df['label']=label\n",
    "df.drop(['source'],axis=1,inplace=True)\n",
    "\n",
    "\n",
    "# key_categories = ['politics','sport','religion','computer','sales','automobile','science','medicine']\n",
    "# cat_dict = {\n",
    "# **dict.fromkeys(['talk.politics.misc','talk.politics.guns','talk.politics.mideast'],'politics'),\n",
    "# **dict.fromkeys( ['rec.sport.hockey','rec.sport.baseball'],'sport'),\n",
    "# **dict.fromkeys( ['soc.religion.christian','talk.religion.misc'],'religion'),\n",
    "# **dict.fromkeys(['comp.windows.x','comp.sys.ibm.pc.hardware','comp.os.ms-windows.misc','comp.graphics','comp.sys.mac.hardware'],'computer'),\n",
    "# **dict.fromkeys( ['misc.forsale'],'sales'),\n",
    "# **dict.fromkeys( ['rec.autos','rec.motorcycles'],'automobile'),\n",
    "# **dict.fromkeys( ['sci.crypt','sci.electronics','sci.space'],'science'),\n",
    "# **dict.fromkeys( ['sci.med'],'medicine') \n",
    "# }\n",
    "# df['label']=df['label'].map(cat_dict)\n",
    "\n",
    "label_encoder = LabelEncoder()  \n",
    "# Encode labels in column 'species'.\n",
    "df['target']= label_encoder.fit_transform(df['label'])\n",
    "\n",
    "\n",
    "#++++++++++++++++++++++++ PICK RANDOM 30 % OF TEST++++++++++++++++++++++++++\n",
    "df = df.sample(frac = 0.01) \n",
    "# dependent and independent variable\n",
    "X_test = df['text']\n",
    "y_test = df['target']\n",
    "#_____________________________________________________________________________________________________________________________________________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "159a2b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3151cfb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred  = fitted_pipe.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fcce140",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "406d6727",
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_proba_pred = pd.DataFrame(fitted_pipe.predict_proba(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2148f01f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
